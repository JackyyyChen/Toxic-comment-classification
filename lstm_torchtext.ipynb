{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    # 大小写\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(\"#\" , \" \")\n",
    "    text = text.replace(\".\" , \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('http?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('www.[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(\"!+\", \"!\", text)\n",
    "\n",
    "#     text = '!'.join(unique_list(text.split('!')))\n",
    "    text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n",
    "    encoded_string = text.encode(\"ascii\", \"ignore\")\n",
    "    decode_string = encoded_string.decode()\n",
    "    return decode_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/a/OneDrive/UNSW/COMP9444/9444_toxic_comment_classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "data_folder_path = './data/'\n",
    "df = pd.read_csv(data_folder_path + 'train.csv')\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].apply(data_cleaning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                  id                                       comment_text  \\\n0   0000997932d777bf  Explanation Why the edits made under my userna...   \n1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2   000113f07ec002fd  Hey man, I'm really not trying to edit war It'...   \n3   0001b41b1c6bb37e  \" More I can do that later on, if no-one else ...   \n4   0001d958c54c6e35  You, sir, are my hero Any chance you remember ...   \n5   00025465d4725e87  \"  Congratulations from me as well, use the to...   \n6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n9   00040093b2687caa  alignment on this subject and which are contra...   \n10  0005300084f90edc  \" Fair use) then the image will be deleted  ho...   \n11  00054a5e18b50dd4  bbq   be a man and lets discuss it-maybe over ...   \n12  0005c987bdfc9d4b  Hey what is it an exclusive group of some WP T...   \n13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n15  00078f8ce7eb276d  \"  Juelz Santanas Age  In , Juelz Santana was ...   \n16  0007e25b2121310b  Bye!   Don't look, come or think of comming ba...   \n17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n19  0009eaea3325de8c  Don't mean to bother you   I see that you thin...   \n\n    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0       0             0        0       0       0              0  \n1       0             0        0       0       0              0  \n2       0             0        0       0       0              0  \n3       0             0        0       0       0              0  \n4       0             0        0       0       0              0  \n5       0             0        0       0       0              0  \n6       1             1        1       0       1              0  \n7       0             0        0       0       0              0  \n8       0             0        0       0       0              0  \n9       0             0        0       0       0              0  \n10      0             0        0       0       0              0  \n11      0             0        0       0       0              0  \n12      1             0        0       0       0              0  \n13      0             0        0       0       0              0  \n14      0             0        0       0       0              0  \n15      0             0        0       0       0              0  \n16      1             0        0       0       0              0  \n17      0             0        0       0       0              0  \n18      0             0        0       0       0              0  \n19      0             0        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation Why the edits made under my userna...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war It'...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\" More I can do that later on, if no-one else ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero Any chance you remember ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00025465d4725e87</td>\n      <td>\"  Congratulations from me as well, use the to...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0002bcb3da6cb337</td>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00031b1e95af7921</td>\n      <td>Your vandalism to the Matt Shirvington article...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00037261f536c51d</td>\n      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00040093b2687caa</td>\n      <td>alignment on this subject and which are contra...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0005300084f90edc</td>\n      <td>\" Fair use) then the image will be deleted  ho...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00054a5e18b50dd4</td>\n      <td>bbq   be a man and lets discuss it-maybe over ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0005c987bdfc9d4b</td>\n      <td>Hey what is it an exclusive group of some WP T...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0006f16e4e9f292e</td>\n      <td>Before you start throwing accusations and warn...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00070ef96486d6f9</td>\n      <td>Oh, and the girl above started her arguments w...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00078f8ce7eb276d</td>\n      <td>\"  Juelz Santanas Age  In , Juelz Santana was ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0007e25b2121310b</td>\n      <td>Bye!   Don't look, come or think of comming ba...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>000897889268bc93</td>\n      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0009801bd85e5806</td>\n      <td>The Mitsurugi point made no sense - why not ar...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0009eaea3325de8c</td>\n      <td>Don't mean to bother you   I see that you thin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train = df['comment_text']\n",
    "X_labels = df[classes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 1, 1, 0, 1, 0]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "\n",
    "X_labels = X_labels.values.tolist()\n",
    "X_labels[6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514\n",
      "torch.Size([1193515, 200])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "\n",
    "# unk_token = \"<pad>\"\n",
    "unk_index = 0\n",
    "glove_vectors = GloVe('twitter.27B', dim=200)\n",
    "print(len(glove_vectors.stoi))\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "glove_vocab.insert_token(\"<pad>\",unk_index)\n",
    "#this is necessary otherwise it will throw runtime error if OOV token is queried\n",
    "glove_vocab.set_default_index(unk_index)\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "print(pretrained_embeddings.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "class MyDataset(IterableDataset):\n",
    "\n",
    "    def __init__(self, dataframe, max_len=100, pad_token='<pad>'):\n",
    "         self.X = dataframe['comment_text'].values\n",
    "         self.Y = dataframe[classes].to_numpy()\n",
    "         self.max_len = max_len\n",
    "         self.pad_token = pad_token\n",
    "         # self.unk_token = unk_token\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for t in range(len(self.X)):\n",
    "            tokens = tokenizer(self.X[t])[:self.max_len]\n",
    "\n",
    "            diff = self.max_len - len(tokens)\n",
    "            # print('diff',diff)\n",
    "            if diff > 0:\n",
    "                tokens += [self.pad_token] * diff\n",
    "                # print('tokens',to\n",
    "            indices = glove_vocab(tokens)\n",
    "            indices = torch.tensor(indices)\n",
    "            result = {\n",
    "                'text': tokens,\n",
    "                'indices': indices,\n",
    "                'label': self.Y[t]\n",
    "            }\n",
    "            yield result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "train_dataset = MyDataset(df, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', '?', 'they', 'weren', \"'\", 't', 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'i', \"'\", 'm', 'retired', 'now', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[0 0 0 0 0 0]\n",
      "tensor([ 19877,    164,     13,  34435,    425,   1477,     29,   7641,   8883,\n",
      "         18462,    830,    377, 361758,     14,    109, 333434,     48,    187,\n",
      "             0,      4,     59,  35320,     46,    191,   2831,    393,     10,\n",
      "          3435,     66,    122,   2323,  18544,  32836,     26,    200,   2768,\n",
      "            48,    187,   9470,     13,  38578,    133,     13,    436,   1737,\n",
      "           765,     10,     48,     72,  22942,    110,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0])\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataset:\n",
    "    print(data['text'])\n",
    "    print(data['label'])\n",
    "    print(data['indices'])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings, num_class, hidden_size, freeze_embeddings = False, is_batch = True):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.is_batch = is_batch\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze = freeze_embeddings, sparse=True)\n",
    "\n",
    "        # print(pretrained_embeddings.shape)\n",
    "\n",
    "        self.lstm = nn.LSTM(pretrained_embeddings.shape[1], hidden_size, num_layers= 1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_class)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    #def attention_net(self, lstm_output):\n",
    "    #    attn_weight_matrix = self.W_s2(torch.tanh(self.W_s1(lstm_output)))\n",
    "    #    attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
    "    #    attn_weight_matrix = nn.functional.softmax(attn_weight_matrix, dim=2)\n",
    "    #    return attn_weight_matrix\n",
    "\n",
    "    def forward(self, indices):\n",
    "        embedded = self.embedding(indices)\n",
    "        #print('embed', embedded.requires_grad)\n",
    "        #print('embedded',embedded.shape)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        #print('lstm_out',lstm_out.requires_grad)\n",
    "        #print('lstm last hidden',hidden[-1].shape)\n",
    "        #print('lstm out', lstm_out.shape)\n",
    "\n",
    "        lstm_out = torch.relu(lstm_out[:,-1,:])\n",
    "        #print('lstm_out',lstm_out.requires_grad)\n",
    "        # print('lstm out', lstm_out.shape)\n",
    "        out = self.fc(lstm_out)\n",
    "        #print('out',out.requires_grad)\n",
    "        #print('out',out.shape)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "## OK let's try to run this model to see if dimensions are correct!\n",
    "#glove_model = TextClassificationModel(pretrained_embeddings, len(classes), hidden_size=64, is_batch=False)\n",
    "\n",
    "#for idx, data in enumerate(train_dataset):\n",
    "#    print(\"---------------------------------\")\n",
    "#    print('next example id ', idx)\n",
    "#    print(\"---------------------------------\")\n",
    "#    # example_text = data['text']\n",
    "#    text_input = data['indices']\n",
    "    # print('tensor_shape: ', text_input.shape)\n",
    "#    model_output = glove_model(text_input)\n",
    "    # fwd = glove_model.forward(text_input)\n",
    "    # print('embedding_bag: ',  fwd.shape)\n",
    "    # print('output_shape: ', model_output.shape)\n",
    "#    print('output: ', model_output)\n",
    "\n",
    "    #if idx == 2:\n",
    "#    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [80]\u001B[0m, in \u001B[0;36m<cell line: 18>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(predictions\u001B[38;5;241m.\u001B[39mfloat(), labels\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m     38\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 39\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_id \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/COMP9444/lib/python3.9/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/COMP9444/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_grad_enabled(True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor((159571 - 35098) / 35098))\n",
    "model = TextClassificationModel(pretrained_embeddings, len(classes), hidden_size=64)\n",
    "\n",
    "print(device)\n",
    "loss_fn.to(device)\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "training_losses = [ None for i in range(epochs)]\n",
    "epoch_count = [i for i in range(1, epochs+1)]\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch_id, batch in enumerate(train_dataloader):\n",
    "\n",
    "\n",
    "\n",
    "        ids = batch['indices'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(ids)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "\n",
    "        predictions = torch.where(probs > 0.5, 1, 0)\n",
    "\n",
    "        loss = loss_fn(predictions.float(), labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Epoch: {} Batch: {} Loss: {}'.format(e, batch_id, loss.item()))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    epoch_loss = np.mean(losses)\n",
    "\n",
    "    training_losses[e] = epoch_loss\n",
    "    print('Epoch: {} Loss: {}'.format(e, epoch_loss))\n",
    "    plt.plot(epoch_count, training_losses, 'r--')\n",
    "    # plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend(['Training Loss', 'Test Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    # torch.save(model.state_dict(), './model_save/lstm_{}.pkl'.format(epochs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}