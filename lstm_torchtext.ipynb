{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    # 大小写\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(\"#\" , \" \")\n",
    "    text = text.replace(\".\" , \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('http?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('www.[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(\"!+\", \"!\", text)\n",
    "\n",
    "#     text = '!'.join(unique_list(text.split('!')))\n",
    "    text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n",
    "    encoded_string = text.encode(\"ascii\", \"ignore\")\n",
    "    decode_string = encoded_string.decode()\n",
    "    return decode_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/a/OneDrive/UNSW/COMP9444/9444_toxic_comment_classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "data_folder_path = './data/'\n",
    "df = pd.read_csv(data_folder_path + 'train.csv')\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].apply(data_cleaning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                  id                                       comment_text  \\\n0   0000997932d777bf  Explanation Why the edits made under my userna...   \n1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2   000113f07ec002fd  Hey man, I'm really not trying to edit war It'...   \n3   0001b41b1c6bb37e  \" More I can do that later on, if no-one else ...   \n4   0001d958c54c6e35  You, sir, are my hero Any chance you remember ...   \n5   00025465d4725e87  \"  Congratulations from me as well, use the to...   \n6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n9   00040093b2687caa  alignment on this subject and which are contra...   \n10  0005300084f90edc  \" Fair use) then the image will be deleted  ho...   \n11  00054a5e18b50dd4  bbq   be a man and lets discuss it-maybe over ...   \n12  0005c987bdfc9d4b  Hey what is it an exclusive group of some WP T...   \n13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n15  00078f8ce7eb276d  \"  Juelz Santanas Age  In , Juelz Santana was ...   \n16  0007e25b2121310b  Bye!   Don't look, come or think of comming ba...   \n17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n19  0009eaea3325de8c  Don't mean to bother you   I see that you thin...   \n\n    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0       0             0        0       0       0              0  \n1       0             0        0       0       0              0  \n2       0             0        0       0       0              0  \n3       0             0        0       0       0              0  \n4       0             0        0       0       0              0  \n5       0             0        0       0       0              0  \n6       1             1        1       0       1              0  \n7       0             0        0       0       0              0  \n8       0             0        0       0       0              0  \n9       0             0        0       0       0              0  \n10      0             0        0       0       0              0  \n11      0             0        0       0       0              0  \n12      1             0        0       0       0              0  \n13      0             0        0       0       0              0  \n14      0             0        0       0       0              0  \n15      0             0        0       0       0              0  \n16      1             0        0       0       0              0  \n17      0             0        0       0       0              0  \n18      0             0        0       0       0              0  \n19      0             0        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation Why the edits made under my userna...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war It'...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\" More I can do that later on, if no-one else ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero Any chance you remember ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00025465d4725e87</td>\n      <td>\"  Congratulations from me as well, use the to...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0002bcb3da6cb337</td>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00031b1e95af7921</td>\n      <td>Your vandalism to the Matt Shirvington article...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00037261f536c51d</td>\n      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00040093b2687caa</td>\n      <td>alignment on this subject and which are contra...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0005300084f90edc</td>\n      <td>\" Fair use) then the image will be deleted  ho...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00054a5e18b50dd4</td>\n      <td>bbq   be a man and lets discuss it-maybe over ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0005c987bdfc9d4b</td>\n      <td>Hey what is it an exclusive group of some WP T...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0006f16e4e9f292e</td>\n      <td>Before you start throwing accusations and warn...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00070ef96486d6f9</td>\n      <td>Oh, and the girl above started her arguments w...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00078f8ce7eb276d</td>\n      <td>\"  Juelz Santanas Age  In , Juelz Santana was ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0007e25b2121310b</td>\n      <td>Bye!   Don't look, come or think of comming ba...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>000897889268bc93</td>\n      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0009801bd85e5806</td>\n      <td>The Mitsurugi point made no sense - why not ar...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0009eaea3325de8c</td>\n      <td>Don't mean to bother you   I see that you thin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "X_train = df['comment_text']\n",
    "X_labels = df[classes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 1, 1, 0, 1, 0]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "\n",
    "X_labels = X_labels.values.tolist()\n",
    "X_labels[6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514\n",
      "torch.Size([1193515, 200])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe, vocab\n",
    "\n",
    "# unk_token = \"<pad>\"\n",
    "unk_index = 0\n",
    "glove_vectors = GloVe('twitter.27B', dim=200)\n",
    "print(len(glove_vectors.stoi))\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "glove_vocab.insert_token(\"<pad>\",unk_index)\n",
    "#this is necessary otherwise it will throw runtime error if OOV token is queried\n",
    "glove_vocab.set_default_index(unk_index)\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "print(pretrained_embeddings.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "class MyDataset(IterableDataset):\n",
    "\n",
    "    def __init__(self, X, Y, max_len=100, pad_token='<pad>'):\n",
    "         self.X = X\n",
    "         self.Y = Y\n",
    "         self.max_len = max_len\n",
    "         self.pad_token = pad_token\n",
    "         # self.unk_token = unk_token\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for t in range(len(self.X)):\n",
    "            tokens = tokenizer(self.X[t])[:self.max_len]\n",
    "            diff = self.max_len - len(tokens)\n",
    "            # print('diff',diff)\n",
    "            if diff > 0:\n",
    "                tokens += [self.pad_token] * diff\n",
    "                # print('tokens',tokens)\n",
    "            result = {\n",
    "                'text': tokens,\n",
    "                'label': self.Y[t]\n",
    "            }\n",
    "            yield result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "train_dataset = MyDataset(X_train, X_labels, MAX_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', '?', 'they', 'weren', \"'\", 't', 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'i', \"'\", 'm', 'retired', 'now', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataset:\n",
    "    print(data['text'])\n",
    "    print(data['label'])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings, num_class, freeze_embeddings = False):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze = freeze_embeddings, sparse=True)\n",
    "\n",
    "        print(pretrained_embeddings.shape)\n",
    "\n",
    "        self.fc = nn.Linear(pretrained_embeddings.shape[1], num_class)\n",
    "        # self.init_weights()\n",
    "\n",
    "    ## 我们需要自定义 init_weights 吗？\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    ## 后续可能要把 text 参数 换成 batch，以便使用 dataloader 来训练\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        print('last padding shape:', embedded[-1].shape)\n",
    "        print('last padding value:', embedded[-1])\n",
    "        print('embedded shape:', embedded.shape)\n",
    "        return self.fc(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1193515, 200])\n"
     ]
    }
   ],
   "source": [
    "glove_model = TextClassificationModel(pretrained_embeddings, len(classes)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "next example id  0\n",
      "---------------------------------\n",
      "['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', '?', 'they', 'weren', \"'\", 't', 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'i', \"'\", 'm', 'retired', 'now', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "token_len:  100\n",
      "indices_len:  100\n",
      "tensor_shape:  torch.Size([100])\n",
      "last padding shape: torch.Size([200])\n",
      "last padding value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)\n",
      "embedded shape: torch.Size([100, 200])\n",
      "output_shape:  torch.Size([100, 6])\n"
     ]
    }
   ],
   "source": [
    "## OK let's try to run this model to see if dimensions are correct!\n",
    "\n",
    "\n",
    "for idx, data in enumerate(train_dataset):\n",
    "    print(\"---------------------------------\")\n",
    "    print('next example id ', idx)\n",
    "    print(\"---------------------------------\")\n",
    "    example_text = data['text']\n",
    "    print(example_text)\n",
    "    print('token_len: ' , len(example_text))\n",
    "    indices = glove_vocab(example_text)\n",
    "    print('indices_len: ' , len(indices))\n",
    "    text_input = torch.tensor(indices)\n",
    "    print('tensor_shape: ', text_input.shape)\n",
    "    model_output = glove_model(text_input)\n",
    "    # fwd = glove_model.forward(text_input)\n",
    "    # print('embedding_bag: ',  fwd.shape)\n",
    "    print('output_shape: ', model_output.shape)\n",
    "\n",
    "    #if idx == 2:\n",
    "    break\n",
    "\n",
    "\n",
    "## TODO: Modified the model with LSTM layers and train it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}