{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from torchtext.vocab import GloVe, vocab\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import nltk\n",
    "def data_cleaning(text):\n",
    "    # 大小写\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(\"#\" , \" \")\n",
    "    text = text.replace(\".\" , \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "\n",
    "\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('http?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub('www.[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "\n",
    "    # Stopwords\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "\n",
    "    encoded_string = text.encode(\"ascii\", \"ignore\")\n",
    "    decode_string = encoded_string.decode()\n",
    "    return decode_string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "data_folder_path = '/mnt/a/OneDrive/UNSW/COMP9444/9444_toxic_comment_classification/data/'\n",
    "df = pd.read_csv(data_folder_path + 'train.csv')\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].apply(data_cleaning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(count    159571.000000\n mean         39.459563\n std          60.610472\n min           0.000000\n 25%          10.000000\n 50%          21.000000\n 75%          43.000000\n max        1411.000000\n Name: comment_text, dtype: float64,\n 225.0)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words(comment):\n",
    "    comment = comment.split()\n",
    "    return len(comment)\n",
    "lens = df['comment_text'].apply(count_words)\n",
    "lens.describe(), np.quantile(lens, 0.98)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(data_folder_path + 'train_cleaned.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0196,  0.2471,  0.0933,  0.9827, -0.4932, -0.5208, -0.5511, -0.2384,\n",
      "         0.0633,  0.2640, -0.0855, -0.0142, -0.2185,  0.0615, -0.0203, -0.5917,\n",
      "        -0.5143, -0.4775,  0.0501, -0.5398, -0.4444,  0.5033,  0.5590, -0.1862,\n",
      "        -0.1925,  0.8136,  0.0792,  0.6563, -0.2354, -0.3717, -0.3733,  0.2547,\n",
      "         0.5859,  0.2547, -1.5402,  0.4177, -0.4178,  0.6288,  0.1763, -0.1376,\n",
      "        -0.0983,  0.4113,  0.1282, -0.9423, -0.8857,  0.9278, -0.1266,  0.5425,\n",
      "         0.6687,  1.1172,  0.1437,  0.1578, -0.1240, -0.2762,  0.0530, -0.0099,\n",
      "        -0.4356, -0.1290,  0.0104,  0.6156,  0.5624,  0.0147,  0.2363,  0.2392,\n",
      "        -0.4270,  0.2027,  0.0283,  0.2958,  0.7260,  0.1783,  0.0921,  0.3728,\n",
      "         0.2069, -0.1167, -0.4945, -0.8139,  0.7111,  0.1753,  0.3670,  1.3172,\n",
      "         0.4816,  0.0983, -0.3783, -0.1295,  0.2076,  0.6489, -0.7640, -0.6700,\n",
      "        -0.2590, -0.8446, -0.0727,  0.3674,  0.7326,  0.3010, -0.8171,  0.6957,\n",
      "         0.1134,  0.1629,  0.4557,  0.0141])\n"
     ]
    }
   ],
   "source": [
    "num_class = len(classes)\n",
    "glove_vectors = GloVe('twitter.27B', dim=100)\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "print(glove_vectors['fucccck'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "glove_vocab.insert_token('<unk>', 0)\n",
    "glove_vocab.set_default_index(0)\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# print(glove_vectors['<unk>'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0.])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained_embeddings[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [57]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m url_dp \u001B[38;5;241m=\u001B[39m IterableWrapper([data_folder_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_cleaned.csv\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m data_dp \u001B[38;5;241m=\u001B[39m FileOpener(url_dp, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdata_dp\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "File \u001B[0;32m~/miniconda3/envs/COMP9444/lib/python3.9/site-packages/torch/utils/data/dataset.py:51\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_co:\n\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torchdata.datapipes.iter import FileOpener,IterableWrapper\n",
    "url_dp = IterableWrapper([data_folder_path + 'train_cleaned.csv'])\n",
    "data_dp = FileOpener(url_dp, mode=\"b\")\n",
    "print(data_dp[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (139337640.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Input \u001B[0;32mIn [56]\u001B[0;36m\u001B[0m\n\u001B[0;31m    \u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class ToxicDataset(Dataset):\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([18, 200])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 631626054400 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [91]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m padded \u001B[38;5;241m=\u001B[39m \u001B[43mpack_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcomment_text\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/COMP9444/lib/python3.9/site-packages/torch/nn/utils/rnn.py:482\u001B[0m, in \u001B[0;36mpack_sequence\u001B[0;34m(sequences, enforce_sorted)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Packs a list of variable length Tensors\u001B[39;00m\n\u001B[1;32m    451\u001B[0m \n\u001B[1;32m    452\u001B[0m \u001B[38;5;124;03mConsecutive call of the next functions: ``pad_sequence``, ``pack_padded_sequence``.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m    a :class:`PackedSequence` object\u001B[39;00m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    481\u001B[0m lengths \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor([v\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m sequences])\n\u001B[0;32m--> 482\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_padded_sequence(\u001B[43mpad_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m)\u001B[49m, lengths, enforce_sorted\u001B[38;5;241m=\u001B[39menforce_sorted)\n",
      "File \u001B[0;32m~/miniconda3/envs/COMP9444/lib/python3.9/site-packages/torch/nn/utils/rnn.py:396\u001B[0m, in \u001B[0;36mpad_sequence\u001B[0;34m(sequences, batch_first, padding_value)\u001B[0m\n\u001B[1;32m    392\u001B[0m         sequences \u001B[38;5;241m=\u001B[39m sequences\u001B[38;5;241m.\u001B[39munbind(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001B[39;00m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001B[39;00m\n\u001B[0;32m--> 396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_value\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: [enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 631626054400 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "padded = pack_sequence(train[\"comment_text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}